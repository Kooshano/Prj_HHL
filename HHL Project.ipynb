{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22884df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit.quantum_info import Statevector\n",
    "\n",
    "from QLS.numpy_linear_solver import NumPyLinearSolver   # classical\n",
    "from QLS.hhl import HHL              # quantum HHL\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43c63db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- user parameters ------------------------------------------------------\n",
    "make_hermitian = True       # True → Hermitian SPD; False → general non-Hermitian\n",
    "target_kappa   = 1e2        # desired condition number κ(A)\n",
    "density        = 0.9        # fraction of nonzero entries (0<density≤1)\n",
    "noise_level    = 1e1       # relative off-diag noise for SPD case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58e8b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- problem definition ---------------------------------------------------\n",
    "NUM_WORK_QUBITS = 4                \n",
    "DIM             = 2 ** NUM_WORK_QUBITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76cf993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- helpers ---------------------------------------------------------------\n",
    "def generate_sparse_spd(n, kappa, density, noise_level):\n",
    "    \"\"\"Hermitian SPD with log-spaced eigenvalues and random sparse off-diag noise.\"\"\"\n",
    "    # 1) log-spaced eigenvalues\n",
    "    eigs = np.logspace(0, np.log10(kappa), n)\n",
    "    # 2) diagonal entries\n",
    "    rows = np.arange(n); cols = rows; data = eigs\n",
    "    A = coo_matrix((data, (rows, cols)), shape=(n, n))\n",
    "    # 3) add symmetric off-diagonal noise\n",
    "    total = n*n\n",
    "    nnz   = int(density*total)\n",
    "    off   = max(nnz - n, 0)\n",
    "    off  -= off % 2\n",
    "    half  = off//2\n",
    "    if half>0:\n",
    "        i = np.random.randint(0,n,half*2)\n",
    "        j = np.random.randint(0,n,half*2)\n",
    "        mask = (i!=j)\n",
    "        i,j = i[mask][:half], j[mask][:half]\n",
    "        eps  = noise_level * eigs.min()\n",
    "        vals = np.random.uniform(-eps, eps, size=half)\n",
    "        A   = A + coo_matrix((vals,(i,j)),shape=(n,n))\\\n",
    "                + coo_matrix((vals,(j,i)),shape=(n,n))\n",
    "    return A.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15b204da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_general(n, kappa, density):\n",
    "    \"\"\"General (non-Hermitian) matrix with approx κ via SVD, then sparsified.\"\"\"\n",
    "    # 1) U, V random orthonormal\n",
    "    U,_  = np.linalg.qr(np.random.randn(n,n))\n",
    "    V,_  = np.linalg.qr(np.random.randn(n,n))\n",
    "    # 2) singular values\n",
    "    s    = np.logspace(0, np.log10(kappa), n)\n",
    "    A    = U @ np.diag(s) @ V.T\n",
    "    # 3) sparsify by zeroing random entries\n",
    "    mask = (np.random.rand(n,n) < density)\n",
    "    A   *= mask\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b22a4747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- build A ----------------------------------------------------------------\n",
    "if make_hermitian:\n",
    "    A_sparse = generate_sparse_spd(DIM, target_kappa, density, noise_level)\n",
    "    A        = A_sparse.toarray()\n",
    "else:\n",
    "    A = generate_general(DIM, target_kappa, density)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3b73f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      " [[ 1.00000000e+00  0.00000000e+00  9.57873801e+00 -3.75589096e+00\n",
      "   8.66067564e+00  0.00000000e+00  1.10433016e+00  0.00000000e+00\n",
      "   7.12710946e+00 -8.26257367e+00  0.00000000e+00 -5.76812741e+00\n",
      "   8.65388878e+00  8.36028444e+00  2.67016711e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  1.35935639e+00 -3.55392775e-01  1.24539848e+00\n",
      "   6.42155800e-02  8.27858840e+00  8.85532769e-02 -5.57756857e-01\n",
      "  -6.66051811e+00 -1.01314952e+01  0.00000000e+00  1.78432842e+00\n",
      "  -8.72528508e+00  6.43294386e+00  2.43228188e+00  2.11850823e+00]\n",
      " [ 9.57873801e+00 -3.55392775e-01  1.84784980e+00  0.00000000e+00\n",
      "   2.73505868e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   5.92689933e+00 -2.33228704e+00 -1.04592649e+01  0.00000000e+00\n",
      "   0.00000000e+00  8.00156018e+00  3.17895631e+00 -1.76426624e+01]\n",
      " [-3.75589096e+00  1.24539848e+00  0.00000000e+00  2.51188643e+00\n",
      "  -7.51677352e+00 -1.23330678e+00  0.00000000e+00  1.21392189e+01\n",
      "  -2.08781105e+00  7.01444298e+00 -6.95811937e+00  0.00000000e+00\n",
      "   0.00000000e+00  8.76747347e-01  4.62597451e+00  0.00000000e+00]\n",
      " [ 8.66067564e+00  6.42155800e-02  2.73505868e+00 -7.51677352e+00\n",
      "   3.41454887e+00  0.00000000e+00  0.00000000e+00 -1.38381059e+01\n",
      "   9.34912737e-01 -8.84149782e+00 -2.88332290e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  7.76593152e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  8.27858840e+00  0.00000000e+00 -1.23330678e+00\n",
      "   0.00000000e+00  4.64158883e+00  2.12298177e+00  9.73118872e+00\n",
      "  -8.59982768e+00  8.95603843e+00  7.31841308e+00  0.00000000e+00\n",
      "   0.00000000e+00 -1.36714630e+00  0.00000000e+00 -4.64198075e-01]\n",
      " [ 1.10433016e+00  8.85532769e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  2.12298177e+00  6.30957344e+00 -4.21622867e+00\n",
      "   2.01272607e-02 -4.34583927e-01  0.00000000e+00  6.57002110e-01\n",
      "   0.00000000e+00  0.00000000e+00 -2.82007285e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -5.57756857e-01  0.00000000e+00  1.21392189e+01\n",
      "  -1.38381059e+01  9.73118872e+00 -4.21622867e+00  8.57695899e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.11712677e+01  1.00937144e+01\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 7.12710946e+00 -6.66051811e+00  5.92689933e+00 -2.08781105e+00\n",
      "   9.34912737e-01 -8.59982768e+00  2.01272607e-02  0.00000000e+00\n",
      "   1.16591440e+01  9.06344842e-01  0.00000000e+00  0.00000000e+00\n",
      "  -7.29384190e+00  0.00000000e+00  3.48087013e+00 -2.65055800e+00]\n",
      " [-8.26257367e+00 -1.01314952e+01 -2.33228704e+00  7.01444298e+00\n",
      "  -8.84149782e+00  8.95603843e+00 -4.34583927e-01  0.00000000e+00\n",
      "   9.06344842e-01  1.58489319e+01  0.00000000e+00  9.82434113e+00\n",
      "  -6.80951986e-02  0.00000000e+00  0.00000000e+00 -4.49698303e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.04592649e+01 -6.95811937e+00\n",
      "  -2.88332290e+00  7.31841308e+00  0.00000000e+00 -1.11712677e+01\n",
      "   0.00000000e+00  0.00000000e+00  2.15443469e+01 -6.96754632e+00\n",
      "   0.00000000e+00  0.00000000e+00  8.99395829e+00  0.00000000e+00]\n",
      " [-5.76812741e+00  1.78432842e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  6.57002110e-01  1.00937144e+01\n",
      "   0.00000000e+00  9.82434113e+00 -6.96754632e+00  2.92864456e+01\n",
      "   0.00000000e+00  0.00000000e+00  1.48041163e+00  0.00000000e+00]\n",
      " [ 8.65388878e+00 -8.72528508e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -7.29384190e+00 -6.80951986e-02  0.00000000e+00  0.00000000e+00\n",
      "   3.98107171e+01 -3.25341564e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 8.36028444e+00  6.43294386e+00  8.00156018e+00  8.76747347e-01\n",
      "   0.00000000e+00 -1.36714630e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -3.25341564e+00  5.41169527e+01  0.00000000e+00 -2.08422283e+00]\n",
      " [ 2.67016711e+00  2.43228188e+00  3.17895631e+00  4.62597451e+00\n",
      "   7.76593152e+00  0.00000000e+00 -2.82007285e+00  0.00000000e+00\n",
      "   3.48087013e+00  0.00000000e+00  8.99395829e+00  1.48041163e+00\n",
      "   0.00000000e+00  0.00000000e+00  7.35642254e+01  0.00000000e+00]\n",
      " [ 0.00000000e+00  2.11850823e+00 -1.76426624e+01  0.00000000e+00\n",
      "   0.00000000e+00 -4.64198075e-01  0.00000000e+00  0.00000000e+00\n",
      "  -2.65055800e+00 -4.49698303e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -2.08422283e+00  0.00000000e+00  1.00000000e+02]]\n",
      "A (dim=16×16), Hermitian? True, κ(A) ≈ 1.896e+01, sparsity=154/256=60.16%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----- checks & print ---------------------------------------------------------\n",
    "is_herm = np.allclose(A, A.conj().T, atol=1e-12)\n",
    "cond_A  = np.linalg.cond(A)\n",
    "nnz     = np.count_nonzero(A)\n",
    "\n",
    "print(\"A =\\n\", A)   # uncomment to see the full matrix\n",
    "\n",
    "print(f\"A (dim={DIM}×{DIM}), Hermitian? {is_herm}, κ(A) ≈ {cond_A:.3e}, \"\n",
    "      f\"sparsity={nnz}/{DIM*DIM}={nnz/(DIM*DIM):.2%}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36e3549b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----- right-hand side -------------------------------------------------------\n",
    "b_vec = np.zeros(DIM, dtype=complex if np.iscomplexobj(A) else float)\n",
    "b_vec[0] = 1\n",
    "b_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "140ad579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- classical solution ----------------------------------------------------\n",
    "classical_res = NumPyLinearSolver().solve(\n",
    "    A,\n",
    "    b_vec / np.linalg.norm(b_vec)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30e6e0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CPU',)\n",
      "Quantum solver took 10.017 seconds.\n"
     ]
    }
   ],
   "source": [
    "# ----- quantum (HHL) solution ------------------------------------------------\n",
    "# calculate the time for the quantum solver\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "backend = AerSimulator(method='statevector',\n",
    "                           device='CPU',\n",
    "                           precision='double') \n",
    "print(backend.available_devices())\n",
    "hhl_solver  = HHL(epsilon=1e-3, quantum_instance=backend)\n",
    "quantum_res = hhl_solver.solve(A, b_vec)\n",
    "\n",
    "def extract_solution(result, n_work_qubits: int) -> np.ndarray:\n",
    "    sv           = Statevector(result.state).data\n",
    "    total_qubits = int(np.log2(len(sv)))\n",
    "    base_index   = 1 << (total_qubits - 1)\n",
    "    amps         = np.array([sv[base_index + i]\n",
    "                             for i in range(2 ** n_work_qubits)])\n",
    "    return result.euclidean_norm * amps / np.linalg.norm(amps)\n",
    "\n",
    "x_classical = classical_res.state\n",
    "x_quantum   = extract_solution(quantum_res, NUM_WORK_QUBITS)\n",
    "# calculate the time taken by the quantum solver\n",
    "end_time = time.time()\n",
    "# print time taken\n",
    "print(f\"Quantum solver took {end_time - start_time:.3f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f81b26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical solution vector: [-0.02728744  0.00406588  0.03169807 -0.03217946  0.00755279  0.04344895\n",
      "  0.00113711  0.01637682  0.03968556 -0.00753147 -0.00309391 -0.00947363\n",
      "  0.01422529  0.00176832 -0.00055284  0.00645799]\n",
      "Quantum   solution vector: [-0.02654512-1.47426613e-14j  0.00277083-1.24197913e-15j\n",
      "  0.03271372+1.96477418e-14j -0.03354268-1.17608745e-14j\n",
      "  0.0048616 +7.62585920e-15j  0.04035254+1.81874325e-14j\n",
      " -0.0006378 -1.06312870e-15j  0.01669702+8.20854207e-15j\n",
      "  0.03721479+1.55509894e-14j -0.00872862-4.82179288e-15j\n",
      " -0.00213701+1.63309516e-15j -0.00864845-5.62694163e-15j\n",
      "  0.01360493+6.23205906e-15j  0.00167302+1.36878614e-15j\n",
      " -0.00030394-1.24317453e-15j  0.00648586+3.95501734e-15j] \n",
      "\n",
      "Classical Euclidean norm: 0.08363167022447981\n",
      "Quantum   Euclidean norm: 0.08129774697240125 \n",
      "\n",
      "‖x_classical − x_quantum‖₂ = 0.005898498418503956\n"
     ]
    }
   ],
   "source": [
    "# ----- results ---------------------------------------------------------------\n",
    "print(\"Classical solution vector:\", x_classical)\n",
    "print(\"Quantum   solution vector:\", x_quantum, \"\\n\")\n",
    "print(\"Classical Euclidean norm:\", classical_res.euclidean_norm)\n",
    "print(\"Quantum   Euclidean norm:\", quantum_res.euclidean_norm, \"\\n\")\n",
    "print(\"‖x_classical − x_quantum‖₂ =\",\n",
    "      np.linalg.norm(x_classical - x_quantum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "116f1799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run to hhl_runs_log.json (total runs: 50)\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Log run results to JSON (robust to malformed file)\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def serialize_complex_vector(vec):\n",
    "    return [[float(c.real), float(c.imag)] for c in vec]\n",
    "\n",
    "record = {\n",
    "    \"timestamp\":             datetime.now().isoformat(),\n",
    "    \"dim\":                   DIM,\n",
    "    \"make_hermitian\":        make_hermitian,\n",
    "    \"is_hermitian\":          bool(is_herm),\n",
    "    \"condition_number\":      cond_A,\n",
    "    \"nnz\":                   nnz,\n",
    "    \"density\":               nnz/(DIM*DIM),\n",
    "    \"noise_level\":           noise_level if make_hermitian else None,\n",
    "    \"time_quantum_sec\":      end_time - start_time,\n",
    "    \"euclid_norm_classical\": classical_res.euclidean_norm,\n",
    "    \"euclid_norm_quantum\":   quantum_res.euclidean_norm,\n",
    "    \"diff_norm\":             float(np.linalg.norm(x_classical - x_quantum)),\n",
    "    \"x_classical\":           serialize_complex_vector(x_classical),\n",
    "    \"x_quantum\":             serialize_complex_vector(x_quantum),\n",
    "    \"matrix\":                A.tolist(),\n",
    "}\n",
    "\n",
    "logfile = \"hhl_runs_log.json\"\n",
    "\n",
    "# Try to load existing data; if it fails or is malformed, overwrite\n",
    "try:\n",
    "    with open(logfile, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(\"Top-level JSON is not a list\")\n",
    "except (FileNotFoundError, json.JSONDecodeError, ValueError):\n",
    "    data = []\n",
    "\n",
    "data.append(record)\n",
    "\n",
    "with open(logfile, \"w\") as f:\n",
    "    json.dump(data, f, indent=2)\n",
    "\n",
    "print(f\"Logged run to {logfile} (total runs: {len(data)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f1d0f6",
   "metadata": {},
   "source": [
    "# Linear Regression using HHL vs Scikit-learn\n",
    "\n",
    "This section demonstrates how to use HHL to solve linear regression problems and compares the results with scikit-learn's LinearRegression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffeff81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: scikit-learn not available. Install with: pip install scikit-learn\n"
     ]
    }
   ],
   "source": [
    "# Import scikit-learn for comparison\n",
    "try:\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.datasets import make_regression\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    SKLEARN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Warning: scikit-learn not available. Install with: pip install scikit-learn\")\n",
    "    SKLEARN_AVAILABLE = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc160952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Linear Regression Parameters -----------------------------------------\n",
    "# Load housing data from CSV\n",
    "HOUSING_CSV = \"housing.csv\"\n",
    "INCLUDE_INTERCEPT = True  # Whether to include intercept term\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5871ba20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded housing.csv: 506 samples, 14 columns\n",
      "Features shape: (506, 13)\n",
      "Target shape: (506,)\n",
      "Target (MEDV) range: [5.00, 50.00]\n",
      "Target (MEDV) mean: 22.53, std: 9.19\n"
     ]
    }
   ],
   "source": [
    "# ----- Load Housing Dataset ------------------------------------------\n",
    "# Load housing.csv (space-separated, Boston Housing dataset)\n",
    "try:\n",
    "    # Try loading as space-separated\n",
    "    data = np.loadtxt(HOUSING_CSV, delimiter=None)  # None means any whitespace\n",
    "    print(f\"Loaded housing.csv: {data.shape[0]} samples, {data.shape[1]} columns\")\n",
    "    \n",
    "    # Boston Housing: last column is target (MEDV), first 13 are features\n",
    "    X = data[:, :-1]  # All columns except last\n",
    "    y = data[:, -1]   # Last column is target\n",
    "    \n",
    "    print(f\"Features shape: {X.shape}\")\n",
    "    print(f\"Target shape: {y.shape}\")\n",
    "    print(f\"Target (MEDV) range: [{y.min():.2f}, {y.max():.2f}]\")\n",
    "    print(f\"Target (MEDV) mean: {y.mean():.2f}, std: {y.std():.2f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading housing.csv: {e}\")\n",
    "    print(\"Falling back to synthetic data...\")\n",
    "    # Fallback to synthetic data\n",
    "    NUM_FEATURES = 4\n",
    "    NUM_SAMPLES = 100\n",
    "    NOISE = 5.0\n",
    "    if SKLEARN_AVAILABLE:\n",
    "        X, y = make_regression(\n",
    "            n_samples=NUM_SAMPLES,\n",
    "            n_features=NUM_FEATURES,\n",
    "            noise=NOISE,\n",
    "            random_state=RANDOM_SEED,\n",
    "            bias=5.0\n",
    "        )\n",
    "    else:\n",
    "        X = np.random.randn(NUM_SAMPLES, NUM_FEATURES)\n",
    "        true_coef = np.random.randn(NUM_FEATURES)\n",
    "        y = X @ true_coef + np.random.randn(NUM_SAMPLES) * NOISE + 5.0\n",
    "    print(f\"Generated synthetic dataset: {X.shape[0]} samples, {X.shape[1]} features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80c16f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added intercept term. Design matrix shape: (506, 14)\n",
      "Normal equations matrix shape: (14, 14)\n",
      "Right-hand side shape: (14,)\n",
      "Condition number of X^T X: 2.28e+08\n",
      "Padded to 16x16 (power of 2)\n",
      "Using 4 work qubits for HHL\n"
     ]
    }
   ],
   "source": [
    "# ----- Prepare Normal Equations for HHL -------------------------------------\n",
    "# Linear regression solves: (X^T X) β = X^T y\n",
    "# This is the normal equation form: A β = b\n",
    "\n",
    "# Add intercept term if requested (add column of ones)\n",
    "if INCLUDE_INTERCEPT:\n",
    "    X_with_intercept = np.column_stack([np.ones(X.shape[0]), X])\n",
    "    print(f\"Added intercept term. Design matrix shape: {X_with_intercept.shape}\")\n",
    "else:\n",
    "    X_with_intercept = X\n",
    "\n",
    "# Compute X^T X (Gram matrix)\n",
    "A_reg = X_with_intercept.T @ X_with_intercept\n",
    "b_reg = X_with_intercept.T @ y\n",
    "\n",
    "print(f\"Normal equations matrix shape: {A_reg.shape}\")\n",
    "print(f\"Right-hand side shape: {b_reg.shape}\")\n",
    "print(f\"Condition number of X^T X: {np.linalg.cond(A_reg):.2e}\")\n",
    "\n",
    "# HHL requires matrix dimension to be a power of 2\n",
    "# Find next power of 2\n",
    "n_features = A_reg.shape[0]\n",
    "next_power_of_2 = 2 ** int(np.ceil(np.log2(n_features)))\n",
    "\n",
    "if next_power_of_2 > n_features:\n",
    "    # Pad the matrix and vector to next power of 2\n",
    "    pad_size = next_power_of_2 - n_features\n",
    "    A_reg_padded = np.zeros((next_power_of_2, next_power_of_2))\n",
    "    A_reg_padded[:n_features, :n_features] = A_reg\n",
    "    # Add small identity to padded diagonal to keep it well-conditioned\n",
    "    A_reg_padded[n_features:, n_features:] = np.eye(pad_size) * 1e-10\n",
    "    \n",
    "    b_reg_padded = np.zeros(next_power_of_2)\n",
    "    b_reg_padded[:n_features] = b_reg\n",
    "    \n",
    "    print(f\"Padded to {next_power_of_2}x{next_power_of_2} (power of 2)\")\n",
    "    A_hhl = A_reg_padded\n",
    "    b_hhl = b_reg_padded\n",
    "    n_work_qubits_reg = int(np.log2(next_power_of_2))\n",
    "else:\n",
    "    A_hhl = A_reg\n",
    "    b_hhl = b_reg\n",
    "    n_work_qubits_reg = int(np.log2(n_features))\n",
    "\n",
    "print(f\"Using {n_work_qubits_reg} work qubits for HHL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f5d392e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical Solution (Normal Equations):\n",
      "  Intercept: 36.4595\n",
      "  Coefficients: [-1.08011358e-01  4.64204584e-02  2.05586264e-02  2.68673382e+00\n",
      " -1.77666112e+01  3.80986521e+00  6.92224640e-04 -1.47556685e+00\n",
      "  3.06049479e-01 -1.23345939e-02 -9.52747232e-01  9.31168327e-03\n",
      " -5.24758378e-01]\n",
      "  MSE: 21.8948\n",
      "  R²: 0.7406\n"
     ]
    }
   ],
   "source": [
    "# ----- Solve with Scikit-learn (Classical) -----------------------------------\n",
    "if SKLEARN_AVAILABLE:\n",
    "    sklearn_model = LinearRegression(fit_intercept=INCLUDE_INTERCEPT)\n",
    "    sklearn_model.fit(X, y)\n",
    "    if INCLUDE_INTERCEPT:\n",
    "        beta_sklearn = np.concatenate([[sklearn_model.intercept_], sklearn_model.coef_])\n",
    "    else:\n",
    "        beta_sklearn = sklearn_model.coef_\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_sklearn = sklearn_model.predict(X)\n",
    "    mse_sklearn = mean_squared_error(y, y_pred_sklearn)\n",
    "    r2_sklearn = r2_score(y, y_pred_sklearn)\n",
    "    \n",
    "    print(\"Scikit-learn Results:\")\n",
    "    if INCLUDE_INTERCEPT:\n",
    "        print(f\"  Intercept: {beta_sklearn[0]:.4f}\")\n",
    "        print(f\"  Coefficients: {beta_sklearn[1:]}\")\n",
    "    else:\n",
    "        print(f\"  Coefficients: {beta_sklearn}\")\n",
    "    print(f\"  MSE: {mse_sklearn:.4f}\")\n",
    "    print(f\"  R²: {r2_sklearn:.4f}\")\n",
    "else:\n",
    "    # Manual solution using normal equations\n",
    "    beta_sklearn = np.linalg.solve(A_reg, b_reg)\n",
    "    y_pred_sklearn = X_with_intercept @ beta_sklearn\n",
    "    mse_sklearn = np.mean((y - y_pred_sklearn)**2)\n",
    "    r2_sklearn = 1 - np.sum((y - y_pred_sklearn)**2) / np.sum((y - y.mean())**2)\n",
    "    \n",
    "    print(\"Classical Solution (Normal Equations):\")\n",
    "    if INCLUDE_INTERCEPT:\n",
    "        print(f\"  Intercept: {beta_sklearn[0]:.4f}\")\n",
    "        print(f\"  Coefficients: {beta_sklearn[1:]}\")\n",
    "    else:\n",
    "        print(f\"  Coefficients: {beta_sklearn}\")\n",
    "    print(f\"  MSE: {mse_sklearn:.4f}\")\n",
    "    print(f\"  R²: {r2_sklearn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6f270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solving with HHL...\n"
     ]
    }
   ],
   "source": [
    "# ----- Solve with HHL (Quantum) ----------------------------------------------\n",
    "print(\"\\nSolving with HHL...\")\n",
    "start_time_hhl = time.time()\n",
    "\n",
    "# Store the norm of b_hhl before HHL normalizes it internally\n",
    "b_hhl_norm = np.linalg.norm(b_hhl)\n",
    "\n",
    "# Use CPU backend (more reliable than GPU)\n",
    "backend_reg = AerSimulator(method='statevector', precision='double')\n",
    "\n",
    "hhl_solver_reg = HHL(epsilon=1e-3, quantum_instance=backend_reg)\n",
    "quantum_res_reg = hhl_solver_reg.solve(A_hhl, b_hhl)\n",
    "\n",
    "# Extract solution\n",
    "def extract_solution_reg(result, n_work_qubits: int, original_dim: int, b_norm: float) -> np.ndarray:\n",
    "    \"\"\"Extract solution vector from HHL result, handling padding and scaling.\n",
    "    \n",
    "    HHL normalizes the input vector internally, so we need to scale the solution\n",
    "    by the original vector's norm to get the correct result.\n",
    "    \"\"\"\n",
    "    sv = Statevector(result.state).data\n",
    "    total_qubits = int(np.log2(len(sv)))\n",
    "    base_index = 1 << (total_qubits - 1)\n",
    "    amps = np.array([sv[base_index + i] for i in range(2 ** n_work_qubits)])\n",
    "    # Extract normalized solution direction\n",
    "    solution_normalized = amps / np.linalg.norm(amps)\n",
    "    # Scale by euclidean norm and by original b norm to account for HHL's internal normalization\n",
    "    solution_full = result.euclidean_norm * b_norm * solution_normalized\n",
    "    # Return only the original dimension (remove padding)\n",
    "    return solution_full[:original_dim].real\n",
    "\n",
    "# Extract solution - n_features now includes intercept if INCLUDE_INTERCEPT\n",
    "beta_hhl = extract_solution_reg(quantum_res_reg, n_work_qubits_reg, n_features, b_hhl_norm)\n",
    "\n",
    "end_time_hhl = time.time()\n",
    "print(f\"HHL solver took {end_time_hhl - start_time_hhl:.3f} seconds.\")\n",
    "\n",
    "# Verify the solution satisfies the normal equations (for debugging)\n",
    "# Check: A_reg @ beta_hhl should be close to b_reg\n",
    "residual = A_reg @ beta_hhl - b_reg\n",
    "print(f\"\\nVerification: ||A @ β_hhl - b|| = {np.linalg.norm(residual):.6e}\")\n",
    "\n",
    "# If the residual is large, try alternative scaling\n",
    "if np.linalg.norm(residual) > 1e-3:\n",
    "    print(\"Warning: Large residual detected. Trying alternative scaling...\")\n",
    "    # Alternative: scale to match the norm of sklearn solution\n",
    "    scale_factor = np.linalg.norm(beta_sklearn) / np.linalg.norm(beta_hhl)\n",
    "    beta_hhl_alt = beta_hhl * scale_factor\n",
    "    residual_alt = A_reg @ beta_hhl_alt - b_reg\n",
    "    print(f\"Alternative scaling factor: {scale_factor:.6f}\")\n",
    "    print(f\"Alternative residual: ||A @ β_hhl_alt - b|| = {np.linalg.norm(residual_alt):.6e}\")\n",
    "    if np.linalg.norm(residual_alt) < np.linalg.norm(residual):\n",
    "        print(\"Using alternative scaling.\")\n",
    "        beta_hhl = beta_hhl_alt\n",
    "\n",
    "# Predictions using HHL coefficients\n",
    "y_pred_hhl = X_with_intercept @ beta_hhl\n",
    "mse_hhl = np.mean((y - y_pred_hhl)**2)\n",
    "r2_hhl = 1 - np.sum((y - y_pred_hhl)**2) / np.sum((y - y.mean())**2)\n",
    "\n",
    "print(\"\\nHHL Results:\")\n",
    "if INCLUDE_INTERCEPT:\n",
    "    print(f\"  Intercept: {beta_hhl[0]:.4f}\")\n",
    "    print(f\"  Coefficients: {beta_hhl[1:]}\")\n",
    "else:\n",
    "    print(f\"  Coefficients: {beta_hhl}\")\n",
    "print(f\"  MSE: {mse_hhl:.4f}\")\n",
    "print(f\"  R²: {r2_hhl:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944582be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Comparison ------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON: HHL vs Scikit-learn/Classical\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nCoefficient Comparison:\")\n",
    "if INCLUDE_INTERCEPT:\n",
    "    print(f\"  Scikit-learn Intercept: {beta_sklearn[0]:.6f}\")\n",
    "    print(f\"  HHL Intercept:          {beta_hhl[0]:.6f}\")\n",
    "    print(f\"  Intercept Difference:   {beta_sklearn[0] - beta_hhl[0]:.6e}\")\n",
    "    print(f\"\\n  Scikit-learn Coefs: {beta_sklearn[1:]}\")\n",
    "    print(f\"  HHL Coefs:          {beta_hhl[1:]}\")\n",
    "    print(f\"  Coef Difference:   {beta_sklearn[1:] - beta_hhl[1:]}\")\n",
    "else:\n",
    "    print(f\"  Scikit-learn: {beta_sklearn}\")\n",
    "    print(f\"  HHL:          {beta_hhl}\")\n",
    "    print(f\"  Difference:   {beta_sklearn - beta_hhl}\")\n",
    "print(f\"  L2 norm of difference: {np.linalg.norm(beta_sklearn - beta_hhl):.6e}\")\n",
    "\n",
    "print(f\"\\nPerformance Metrics:\")\n",
    "print(f\"  {'Metric':<20} {'Scikit-learn':<15} {'HHL':<15} {'Difference':<15}\")\n",
    "print(f\"  {'-'*20} {'-'*15} {'-'*15} {'-'*15}\")\n",
    "print(f\"  {'MSE':<20} {mse_sklearn:<15.4f} {mse_hhl:<15.4f} {abs(mse_sklearn - mse_hhl):<15.6e}\")\n",
    "print(f\"  {'R²':<20} {r2_sklearn:<15.4f} {r2_hhl:<15.4f} {abs(r2_sklearn - r2_hhl):<15.6e}\")\n",
    "\n",
    "print(f\"\\nRelative Error:\")\n",
    "relative_error = np.linalg.norm(beta_sklearn - beta_hhl) / np.linalg.norm(beta_sklearn)\n",
    "print(f\"  ‖β_sklearn - β_hhl‖ / ‖β_sklearn‖ = {relative_error:.6e}\")\n",
    "\n",
    "print(f\"\\nTiming:\")\n",
    "print(f\"  HHL computation time: {end_time_hhl - start_time_hhl:.3f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d21fc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Visualization (if matplotlib available) ------------------------------\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Plot 1: Coefficient comparison\n",
    "    x_pos = np.arange(len(beta_sklearn))\n",
    "    width = 0.35\n",
    "    axes[0].bar(x_pos - width/2, beta_sklearn, width, label='Scikit-learn', alpha=0.8)\n",
    "    axes[0].bar(x_pos + width/2, beta_hhl, width, label='HHL', alpha=0.8)\n",
    "    axes[0].set_xlabel('Feature Index')\n",
    "    axes[0].set_ylabel('Coefficient Value')\n",
    "    axes[0].set_title('Regression Coefficients Comparison')\n",
    "    axes[0].set_xticks(x_pos)\n",
    "    axes[0].set_xticklabels([f'β{i}' for i in range(len(beta_sklearn))])\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Predicted vs Actual\n",
    "    axes[1].scatter(y, y_pred_sklearn, alpha=0.6, label='Scikit-learn', s=50)\n",
    "    axes[1].scatter(y, y_pred_hhl, alpha=0.6, label='HHL', s=50, marker='x')\n",
    "    # Perfect prediction line\n",
    "    min_val = min(y.min(), y_pred_sklearn.min(), y_pred_hhl.min())\n",
    "    max_val = max(y.max(), y_pred_sklearn.max(), y_pred_hhl.max())\n",
    "    axes[1].plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.5, label='Perfect prediction')\n",
    "    axes[1].set_xlabel('Actual y')\n",
    "    axes[1].set_ylabel('Predicted y')\n",
    "    axes[1].set_title('Predicted vs Actual Values')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Matplotlib not available. Skipping visualization.\")\n",
    "    print(\"Install with: pip install matplotlib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5bdb3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HHL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
